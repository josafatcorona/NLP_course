{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e21a1c6",
   "metadata": {},
   "source": [
    "<h1>Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0fee32",
   "metadata": {},
   "source": [
    "## Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3859acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazi dog's back.\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e768f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc[4],doc[4].tag_,doc[4].pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243a623",
   "metadata": {},
   "source": [
    "## Fine-grained Part-of-speech Tags\n",
    "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
    "<table>\n",
    "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbe8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I read books on NLP.')\n",
    "r = doc[1]\n",
    "\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85472e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'I read a book on NLP.')\n",
    "r = doc[1]\n",
    "\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7092e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazi dog's back.\")\n",
    "# Count the frequencies of different coarse-grained POS tags:\n",
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.vocab[84].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb7669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the different fine-grained tags:\n",
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"The quick brown fox jumped over the lazi dog's back.\")\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc,style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe818df",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={'distance':110,'compact':True,'color':'yellow','bg':'#09a3d5','font':'Times'}\n",
    "displacy.render(doc,style='dep',jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=nlp(u\"This is a sentence. This is another sentence, possibly longer than the other.\" )\n",
    "spans= list(doc2.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695bf13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.serve(spans,style='dep',options={'distance':110},auto_select_port=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865007d",
   "metadata": {},
   "source": [
    "<h1>Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c18d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b551c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabe719",
   "metadata": {},
   "source": [
    "## Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start, ent.end, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74d5bd",
   "metadata": {},
   "source": [
    "## NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Named Entity to a Span\n",
    "doc = nlp(u'Tesla to build a U.K. factory for $6 million')\n",
    "# Right now, spaCy does not recognize \"Tesla\" as a company.\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG']  \n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = Span(doc, 0, 1, label=ORG)\n",
    "\n",
    "# Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e9aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03352bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
    "          u'If successful, the vacuum-cleaner will be our first product.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PhraseMatcher and create a matcher object:\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b899ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the desired phrase patterns:\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the patterns to our matcher object:\n",
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "\n",
    "# Apply the matcher to our Doc object:\n",
    "matches = matcher(doc)\n",
    "\n",
    "# See what matches occur:\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b217763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create Spans from each match, and create named entities from them:\n",
    "# from spacy.tokens import Span\n",
    "PROD = doc.vocab.strings[u'PRODUCT']\n",
    "new_ents = [Span(doc, match[1],match[2],label=PROD) for match in matches]\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d433da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ea954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([ent for ent in doc.ents if ent.label_=='MONEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Import the displaCy library\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1547b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, Sony sold only 7 thousand Walkman music players.')\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Sentences Line by Line\n",
    "for sent in doc.sents:\n",
    "    displacy.render(nlp(sent.text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccacbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **NOTE**: If a span does not contain any entities, displaCy will issue a harmless warning:\n",
    "doc2 = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, my kids sold a lot of lemonade.')\n",
    "for sent in doc2.sents:\n",
    "    displacy.render(nlp(sent.text), style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca775f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Specific Entities\n",
    "options = {'ents': ['ORG', 'PRODUCT']}\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed68a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing Colors and Effects\n",
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', 'PRODUCT': 'radial-gradient(yellow, green)'}\n",
    "options = {'ents': ['ORG', 'PRODUCT'], 'colors':colors}\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b60bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacy.serve(doc, style='ent', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6e208",
   "metadata": {},
   "source": [
    "# Sentence Segmentation\n",
    "In **spaCy Basics** we saw briefly how Doc objects are divided into sentences. In this section we'll learn how sentence segmentation works, and how to set our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17215419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69652d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# From Spacy Basics:\n",
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8eb0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2e1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(doc.sents[1])this is not subscriptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e04d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instead yo can do this\n",
    "doc_sents = [sent for sent in doc.sents]\n",
    "doc_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaefaac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "# Now you can access individual sentences:\n",
    "print(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6754870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa2203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98052748",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'\"Management is doing the right things; leadership is doing the right things.\" -Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f476df6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Management is doing the right things; leadership is doing the right things.\" -Peter Drucker'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618ea72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing the right things; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ece1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143b47a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"set_custom_boundaries\", before='parser')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c24f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# Re-run the Doc object creation:\n",
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d40314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "# Changing the Rules\n",
    "nlp = spacy.load('en_core_web_sm')  # reset to the original\n",
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n",
    "\n",
    "# SPACY DEFAULT BEHAVIOR:\n",
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eb75376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CHANGING THE RULES\n",
    "# from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "# def split_on_newlines(doc):\n",
    "#     start = 0\n",
    "#     seen_newline = False\n",
    "#     for word in doc:\n",
    "#         if seen_newline:\n",
    "#             yield doc[start:word.i]\n",
    "#             start = word.i\n",
    "#             seen_newline = False\n",
    "#         elif word.text.startswith('\\n'): # handles multiple occurrences\n",
    "#             seen_newline = True\n",
    "#     yield doc[start:]      # handles the last group of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fbf769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n",
    "# nlp.add_pipe(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb5cd784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.custom_sentence_segmenter(doc)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.tokenizer_exceptions import URL_PATTERN\n",
    "from spacy.tokens import Doc\n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.language import Language\n",
    "@Language.component(\"custom_sentence_segmenter\")\n",
    "def custom_sentence_segmenter(doc):\n",
    "    # Definir las reglas de segmentaci√≥n personalizadas\n",
    "    infixes = tuple([r\"\\n\"] + list(Doc.DEFAULT_INFIXES))\n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "    # A√±adir una l√≥gica personalizada para la segmentaci√≥n de oraciones\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    for word in doc:\n",
    "        if seen_newline:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif infix_re.search(word.text) or word.text.startswith('\\n'):\n",
    "            seen_newline = True\n",
    "    yield doc[start:]  # manejar el √∫ltimo grupo de tokens\n",
    "\n",
    "# Agregar el componente personalizado al pipeline de spaCy\n",
    "nlp.add_pipe(\"custom_sentence_segmenter\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a53d41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E005] Pipeline component 'custom_sentence_segmenter' returned <class 'generator'> instead of a Doc. If you're using a custom component, maybe you forgot to return the processed Doc?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmystring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m([token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sent])\n",
      "File \u001b[1;32mD:\\VirtualEnvs\\NLP_course\\lib\\site-packages\\spacy\\language.py:1018\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1016\u001b[0m         error_handler(name, proc, [doc], e)\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, Doc):\n\u001b[1;32m-> 1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE005\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, returned_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc)))\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: [E005] Pipeline component 'custom_sentence_segmenter' returned <class 'generator'> instead of a Doc. If you're using a custom component, maybe you forgot to return the processed Doc?"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b24e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
